---
title: Links for Gen AI
author: Hohastudios
date: 2024-03-24
category: blog
layout: post
---

# Chat For RTX

Nvidia’s LLM local chatbot that can ingest pdf and YouTube transcripts. It uses tensorllm Python as a base.

It might be a better option to use gpt4all client


Some pitfalls that may occur

1. Download and install from https://www.nvidia.com/en-us/ai-on-rtx/chatrtx/

2. You may only get mistral 7b on a 8GB card, for llama a 16Gb card is needed. Over 30GB of hard drive space is required for model and dependencies

3. Pre-requisites, if you have Python already installed you may encounter problems installing, despite it using venv. Installation deploys Python 3.10.9 and dependencies, if you already had Python and conflicting dependencies it may cause several problems.

Note: option to clean also will not yield a clean slate, it just deletes certain directories, and when reinstall it misses those original directories out