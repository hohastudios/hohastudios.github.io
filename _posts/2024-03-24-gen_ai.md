---
title: Links for Gen AI
author: Hohastudios
date: 2024-03-24
category: blog
layout: post
---

# Gpt4all
Gpt4all is an offline LLM chat client, it also provides chat models. 

It is possible to ingest pdfs as contexts via the localdocs plugin. You will need the very model installed approx 45mb installed first to ingest. The model itself cannot be used to chat with. Responses return back as exclamation marks.
Installation is very straightforward, it can 'run' on consumer grade cpus but the models nonetheless requires big VRAM in order to run responses fast. Minimum requirement 8gb video card for models like mistral and falcon. 

Download from here https://gpt4all.io/index.html
